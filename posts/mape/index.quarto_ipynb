{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"MAPE and its pitfalls\"\n",
        "description: \"Why MAPE should not be your first choice\"\n",
        "date: 09-01-2024\n",
        "categories: [MAPE, Data Science, Time Series] # self-defined categories\n",
        "image: ruff.png\n",
        "draft: false\n",
        "tbl-cap-location: top\n",
        "---\n",
        "\n",
        "\n",
        "<!-- :::{.cell}\n",
        "![](ruff.png){fig-align=\"center\"}\n",
        "::: -->\n",
        "\n",
        "\n",
        "Hello guys!\n",
        "I want to talk a widely used metric, specially in time series modelling, which it is MAPE.\n",
        "MAPE is a largely used metric because has the following benefits:\n",
        "\n",
        "+ It is a percentage metric; so, it can be used to compare time series with different units. \n",
        "+ It is largely used. People specially from other fields use it without knowing that are using it because it is so straight forward and natural.\n",
        "\n",
        "I will give an example for the last bit: Let's suppose that a salesperson had to sell 100 pairs of boots, but he sold 80, so how far is he from the target? Well, (80-100)/100 = -0,20 = -20%. So the salesperson is 20% far from the target. The formula for `MAPE` can be described as:\n",
        "\n",
        "$$\\text{MAPE} = \\frac{\\sum_{i=1}^{n} \\left| \\frac{y_i - \\hat{y}_i}{y_i} \\right|}{n}$$\n",
        "\n",
        "which is so intuitive. However, behind this popularity, MAPE has several pitfalls, specially when working with high number of time series at the same time:\n",
        "\n",
        "## *MAPE* is a biased metric: \n",
        "  \n",
        "To give a simple example, let's suppose that our `ypred` is 100; if the `yreal` is 150, we have a MAPE equals to 0.33, in constrat to MAPE equals 1 if `yreal` is 50. So, MAPE will always push toward to biased underforecasting.\n",
        "\n",
        "The following table ilustrate this:\n",
        "\n",
        "\n",
        "```{css, echo=FALSE}\n",
        ".center-table table {\n",
        "  width: 50%;\n",
        "  margin-left: auto;\n",
        "  margin-right: auto;\n",
        "}\n",
        "```\n",
        "\n",
        "\n",
        "::: {.center-table}\n",
        "\n",
        "| y_true | y_pred | MAE | MAPE | MSE  |\n",
        "|-------:|-------:|----:|-----:|-----:|\n",
        "| 100    | 150    | 50  | 0.50 | 2500 |\n",
        "| 100    | 50     | 50  | 0.50 | 2500 |\n",
        "| 150    | 100    | 50  | 0.33 | 2500 |\n",
        "| 50     | 100    | 50  | 1.00 | 2500 |\n",
        "\n",
        ": Ilustration of a case when MAPE is biased\n",
        "\n",
        ":::\n",
        "\n",
        "Check that MAE and MSE behave as expected (they don't bias for under/over forecasts).\n",
        "\n",
        "## *MAPE* is not define when `y_true` is zero\n",
        "\n",
        "The denominator of mape is *y_true*. So, MAPE might return `NaN` on your programming software or `Inf`. In order to \"fix\" it, what many people do is to set y_true to a small value near to zero, which is what `sklearn.metrics.mean_average_percentage_error` do (setting y_true to $2.22x10^-16$). But it gives other problems: \n",
        "    1. Setting y_true to $2.22x10^-16$ will lead to a even higher MAPE number;\n",
        "    2. You will never know a \"true\" value of the error for this series;\n",
        "    3. Your prediction will be compromised even if your predictions are really good (let's say 0.00001); \n",
        "    4. If you need to concilliate the metric of this series with other series, your comparison will be compromised because the resulting MAPE will be towards a very high number.\n",
        "\n",
        "In practical terms, see how MAPE will behave if for a true value of 0, we set 9E-17 for the last two rows of the table:\n",
        "\n",
        "| y_true | y_pred | MAE | MAPE       | MSE  |\n",
        "|-------:|-------:|----:|-----------:|-----:|\n",
        "| 0      | 0.5    | 0.5 | #DIV/0!    | 0.25 |\n",
        "| 0      | 1.5    | 1.5 | #DIV/0!    | 2.25 |\n",
        "| 9E-17  | 0.5    | 0.5 | 5.55x10^15 | 0.25 |\n",
        "| 9E-17  | 1.5    | 1.5 | 1.67x10^16 | 2.25 |\n",
        "\n",
        ": Impact in MAPE when y_true is zero or near zero {#tbl-impact}\n",
        "\n",
        "Check that MAE and MSE behave as expected (are not impacted when y_true is zero or 9E-17).\n",
        "\n",
        "Others also don't calculate the forecast for these points, but you will end up with same problem as number 2.\n",
        "\n",
        "\n",
        "## MAPE does not minimizes the error towards the mean value\n",
        "\n",
        "This is not a pitfall, but it is a warning, because usually people want to be right on *average*, and this is not what MAPE does. In constrast, it will give a prediction towards a biased median, if I can so. \n",
        "\n",
        "\n",
        "A very good resource to read about is [shortcomings of MAPE](https://stats.stackexchange.com/questions/299712/what-are-the-shortcomings-of-the-mean-absolute-percentage-error-mape), that will lead to many other resources.\n",
        "\n",
        "In order to overcome the asymmetry problem of MAPE, sMAPE and other adjusted MAPEs were proposed, but no one of them have good properties: they are still undefined if `y_true` and `y_pred` are zero, [check it out](https://robjhyndman.com/hyndsight/smape/). As opposite to MAPE, \n"
      ],
      "id": "be2824d6"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}